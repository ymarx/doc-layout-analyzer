#!/usr/bin/env python3
"""
ë‹¤ì´ì–´ê·¸ë¨ ë‚´ìš© ë¶„ì„ - í”„ë¡œì„¸ìŠ¤ íë¦„ ì¶”ì¶œ
"""

import asyncio
import re
from src.parsers.unified_docx_parser import UnifiedDocxParser

async def analyze_diagram_content():
    """ë‹¤ì´ì–´ê·¸ë¨ ë‚´ìš© ë¶„ì„"""
    print("ğŸ¨ ë‹¤ì´ì–´ê·¸ë¨ ë‚´ìš© ë¶„ì„")
    print("=" * 60)

    parser = UnifiedDocxParser()
    parser.parsing_mode = 'enhanced'

    result = await parser.parse("../ê¸°ìˆ ê¸°ì¤€_ì˜ˆì‹œ.docx")

    if result.success:
        content = result.content
        raw_content = content.get('raw_content', {})

        # 1. ëª¨ë“  í…ìŠ¤íŠ¸ì—ì„œ í”„ë¡œì„¸ìŠ¤ íë¦„ ì°¾ê¸°
        print("1. í…ìŠ¤íŠ¸ì—ì„œ í”„ë¡œì„¸ìŠ¤ íë¦„ íŒ¨í„´ ê²€ìƒ‰")
        print("-" * 40)

        # ë‹¨ë½ì—ì„œ ê²€ìƒ‰
        flow_patterns = [
            r'(\d+\.\s*[^â†’\n]+)(?:\s*â†’\s*(\d+\.\s*[^â†’\n]+))+',  # 1. xxx â†’ 2. xxx
            r'([^â†’\n]+)\s*â†’\s*([^â†’\n]+)(?:\s*â†’\s*([^â†’\n]+))*',  # xxx â†’ yyy â†’ zzz
            r'â‘ ([^â‘¡â‘¢â‘£â‘¤]+)â‘¡([^â‘¢â‘£â‘¤]+)â‘¢?([^â‘£â‘¤]+)?â‘£?([^â‘¤]+)?â‘¤?(.+)?'  # â‘  â‘¡ â‘¢ â‘£ â‘¤ íŒ¨í„´
        ]

        found_flows = []

        for i, para in enumerate(raw_content.get('paragraphs', [])):
            text = para.get('text', '') if isinstance(para, dict) else str(para)

            # í”„ë¡œì„¸ìŠ¤ íë¦„ íŒ¨í„´ ê²€ìƒ‰
            for pattern_name, pattern in enumerate(flow_patterns):
                matches = re.finditer(pattern, text)
                for match in matches:
                    found_flows.append({
                        'paragraph_index': i,
                        'pattern_type': pattern_name,
                        'text': text,
                        'match_groups': match.groups(),
                        'full_match': match.group(0)
                    })

        if found_flows:
            print("âœ… ë°œê²¬ëœ í”„ë¡œì„¸ìŠ¤ íë¦„:")
            for flow in found_flows:
                print(f"   íŒ¨ëŸ¬ê·¸ë˜í”„ {flow['paragraph_index']}: {flow['full_match'][:100]}...")
                if flow['match_groups']:
                    steps = [step for step in flow['match_groups'] if step and step.strip()]
                    print(f"   ë‹¨ê³„: {' â†’ '.join(steps)}")
                print()

        # 2. íŠ¹ì • í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ (ë…¸ì—´í™•ë³´, í†µê¸°ì„±í™•ë³´, í’ëŸ‰í™•ë³´, ì¡°ì—…ë„ìƒìŠ¹)
        print("2. íŠ¹ì • í”„ë¡œì„¸ìŠ¤ í‚¤ì›Œë“œ ê²€ìƒ‰")
        print("-" * 40)

        process_keywords = [
            "ë…¸ì—´í™•ë³´", "í†µê¸°ì„±í™•ë³´", "í’ëŸ‰í™•ë³´", "ì¡°ì—…ë„ìƒìŠ¹", "ì¡°ì—…ë„ ìƒìŠ¹",
            "ì¦ê´‘", "ì¦ì‚°", "ì—°í™”ìœµì°©ëŒ€í˜•ì„±", "ì—°í™”ìœµì°©ëŒ€ í˜•ì„±"
        ]

        keyword_locations = {}
        for keyword in process_keywords:
            keyword_locations[keyword] = []

        for i, para in enumerate(raw_content.get('paragraphs', [])):
            text = para.get('text', '') if isinstance(para, dict) else str(para)
            for keyword in process_keywords:
                if keyword in text:
                    keyword_locations[keyword].append({
                        'paragraph': i,
                        'context': text[:200] + '...' if len(text) > 200 else text
                    })

        print("âœ… ë°œê²¬ëœ í”„ë¡œì„¸ìŠ¤ í‚¤ì›Œë“œ:")
        for keyword, locations in keyword_locations.items():
            if locations:
                print(f"   ğŸ”¹ {keyword}: {len(locations)}íšŒ ë°œê²¬")
                for loc in locations[:2]:  # ì²˜ìŒ 2ê°œë§Œ í‘œì‹œ
                    print(f"      â””â”€ ë¬¸ë‹¨ {loc['paragraph']}: {loc['context']}")

        # 3. ë‹¤ì´ì–´ê·¸ë¨ ì˜ì—­ ìƒì„¸ ë¶„ì„
        print("\n3. ë‹¤ì´ì–´ê·¸ë¨ ì˜ì—­ ìƒì„¸ ë¶„ì„")
        print("-" * 40)

        diagrams = raw_content.get('diagrams', [])
        print(f"âœ… ê°ì§€ëœ ë‹¤ì´ì–´ê·¸ë¨: {len(diagrams)}ê°œ")

        # XML êµ¬ì¡°ì—ì„œ ë” ìƒì„¸í•œ ì •ë³´ ì°¾ê¸°
        xml_struct = raw_content.get('xml_structure', {})
        if xml_struct:
            # ë‹¤ì´ì–´ê·¸ë¨ ê´€ë ¨ ìš”ì†Œë“¤ ì°¾ê¸°
            drawing_elements = []

            print("   XMLì—ì„œ ë‹¤ì´ì–´ê·¸ë¨ ê´€ë ¨ ìš”ì†Œ ê²€ìƒ‰ ì¤‘...")
            # ì´ê±´ ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” XML íŒŒì‹±ìœ¼ë¡œ í•´ì•¼ í•¨
            print("   (ìƒì„¸ XML ë¶„ì„ í•„ìš”)")

        # 4. ì‹œí€€ìŠ¤ ì¶”ì¶œ ì‹œë„
        print("\n4. í”„ë¡œì„¸ìŠ¤ ì‹œí€€ìŠ¤ ì¬êµ¬ì„±")
        print("-" * 40)

        # ë°œê²¬ëœ í‚¤ì›Œë“œë“¤ì„ ìˆœì„œëŒ€ë¡œ ì •ë ¬ ì‹œë„
        if any(keyword_locations.values()):
            print("âœ… ì¶”ì¶œëœ í”„ë¡œì„¸ìŠ¤ íë¦„ ì¬êµ¬ì„±:")

            # ì¼ë°˜ì ì¸ ì œì²  í”„ë¡œì„¸ìŠ¤ ìˆœì„œë¡œ ì •ë ¬
            expected_sequence = [
                "ë…¸ì—´í™•ë³´", "í†µê¸°ì„±í™•ë³´", "í’ëŸ‰í™•ë³´", "ì—°í™”ìœµì°©ëŒ€í˜•ì„±",
                "ì¡°ì—…ë„ìƒìŠ¹", "ì¦ê´‘", "ì¦ì‚°"
            ]

            found_sequence = []
            for step in expected_sequence:
                if keyword_locations.get(step) or keyword_locations.get(step.replace("ìƒìŠ¹", " ìƒìŠ¹")):
                    found_sequence.append(step)

            if found_sequence:
                print("   ğŸ”„ ì¬êµ¬ì„±ëœ í”„ë¡œì„¸ìŠ¤:")
                for i, step in enumerate(found_sequence):
                    arrow = " â†’ " if i < len(found_sequence) - 1 else ""
                    print(f"   {i+1}. {step}{arrow}", end="")
                print()

                # ê° ë‹¨ê³„ì˜ ìƒì„¸ ì •ë³´
                print("\n   ğŸ“‹ ê° ë‹¨ê³„ ìƒì„¸:")
                for step in found_sequence:
                    locs = keyword_locations.get(step, [])
                    if locs:
                        print(f"   â€¢ {step}: {locs[0]['context'][:100]}...")

        print("\n" + "=" * 60)
        print("ğŸ’¡ ë‹¤ì´ì–´ê·¸ë¨ íŒŒì‹± ê°œì„  ë°©í–¥:")
        print("   1. XMLì—ì„œ drawing/shape ìš”ì†Œì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
        print("   2. í…ìŠ¤íŠ¸ë°•ìŠ¤ì™€ í™”ì‚´í‘œì˜ ìœ„ì¹˜ ê´€ê³„ ë¶„ì„")
        print("   3. í”„ë¡œì„¸ìŠ¤ íë¦„ íŒ¨í„´ ì¸ì‹ ê°•í™”")
        print("   4. ìˆœì„œ ì¶”ë¡  ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„")

if __name__ == "__main__":
    asyncio.run(analyze_diagram_content())